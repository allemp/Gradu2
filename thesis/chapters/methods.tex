\chapter{Methods}
\label{chap:methods}

%--------------------------------------------------------------------------------------------------------------------------------------------
\section{Research setup}
\subsection{Scope}

\improvement{TODO Scope}

\improvement{TODO different models, different datasets}

\improvement{TODO Vertailukriteeristö: tapana ohjelmistopuolella + tapana koneoppimispuolella}

\improvement{TODO different resources (memory, time, accuracy)}

This thesis uses a methodology for machine learning experiment design \parencite{fernandez-lozanoMethodologyDesignExperiments2016}. The methodology consists of a workflow with the following steps: Dataset, Data preprocessing, Model Learning and Best Model Selection. 


\subsection{Research Questions}
This master's thesis asks the following research questions:
\begin{itemize}
    \item \emph{RQ1}: How do changes in hyperparameters affect system performance during model training?
    \item \emph{RQ2}: How does early stopping on system performance criteria affect computational budgets during model training?
          
\end{itemize}

\section{Experimental setup}

\subsection{Software and Hardware}

Experiments were performed using Ray Tune (2.7.1) \parencite{liawTuneResearchPlatform2018}. MLFlow (2.7.1) \parencite{chenDevelopmentsMLflowSystem2020} was used for recording metrics and tracking experiments. Scikit-learn (1.3.2) \parencite{pedregosaScikitlearnMachineLearning2011} for training, collecting machine learning performance metrics and evaluating machine learning models. Psutil \parencite{rodolaGiampaoloPsutil2023} was used for collecting system performance metrics from the operating system. Hardware used to perform the experiments consisted of Intel Core i7-9700 @ 3.00GHz CPU and Nvidia 3060 GPU.

\subsection{Datasets}

%\improvement{TODO MNIST}
%\improvement{TODO https://www.openml.org/search?type=data\&status=active\&qualities.NumberOfClasses=\%3D_2\&id=31}
%\improvement{TODO https://www.openml.org/search?type=data\&sort=runs\&id=42731}
%\improvement{TODO NYC Taxi https://www.openml.org/search?type=data\&sort=runs\&id=42729&status=active}

Mnist dataset was chosen because of popularity and familiarity in the machine learning community. The rest of the datasets were chosen by hand instead of randomly sampled to represent small and large datasets in both classification and regression tasks, because the repository is unbalanced and contains a lot of very similar datasets. Table~\ref{table:datasets} summarizes the machine learning task and dimensionality of the datasets. The datasets are loaded using the Penn Machine Learning Benchmark \parencite{olsonPMLBLargeBenchmark2017} python package and consist of input features and a target variable.

\begin{table}[h]
    \centering
    \begin{tabular}{lllll}
        \toprule
        Dataset        & Type    & Task           & Examples & Features \\
        \midrule
        mnist          & image   & classification & 70000    & 784      \\
        kddcup         & tabular & classification & 494020   & 41       \\
        diabetes       & tabular & classification & 768      & 8        \\
        1191\_BNG\_pbc & tabular & regression     & 1000000  & 19       \\
        529\_pollen    & tabular & regression     & 3848     & 5        \\
        \bottomrule
    \end{tabular}
    \caption{Summary of the datasets used.}
    \label{table:datasets}
\end{table}

\subsection{Metrics and evaluation}
Metrics to be evaluated can be divided into machine learning metrics and system performance metrics and are summarized in Table~\ref{table:metrics}. Training loss was computed with each training step and the rest of the metrics were computed every $100$ training steps. Machine learning metrics were computed using scikit-learn \parencite{pedregosaScikitlearnMachineLearning2011} and system performance metrics were collected from the operating system using psutil \parencite{rodolaGiampaoloPsutil2023}. 

In accordance with Ray documentation \parencite{therayteamMemoryManagementRay} to avoid double counting memory used by the object store the memory usage of the worker was computed in the following way:

\[ \text{memory} = \text{resident set size (RSS)} - \text{shared memory usage (SHR)} \]

Machine learning models were validated by splitting the dataset into a $70\%$ training set and a $30\%$ test set. To make sure that measurements are not sensitive to chosen data five-fold cross validation using the training set was performed when tuning hyperparameters.

\begin{table}[h]
    \centering
    \begin{tabular}{llll}
        \toprule
        Metric                     & Type               \\
        \midrule
        training loss              & machine learning   \\
        validation loss            & machine learning   \\
        accuracy                   & machine learning   \\
        root mean square error     & machine learning   \\
        average training step time & system performance \\
        total training time        & system performance \\
        cpu (\%)                   & system performance \\
        memory (MB)                & system performance \\
        
        \bottomrule
    \end{tabular}
    \caption{Summary of the metrics}
    \label{table:metrics}
\end{table}


\subsection{Algorithms}

Algorithms were chosen to support training in batches without being computationally heavy. Linear regression, logistic regression and support vector machine (SVM) are based on stochastic gradient descent (SGD) implementation found in Scikit-learn \parencite{pedregosaScikitlearnMachineLearning2011}. Algorithms and hyperparameters are summarized in Table~\ref{table:algorithms}. Model training, evaluation and hyperparameter optimization was performed in parallel with each worker process using one CPU core each.

Hyperparameters such as batch size, learning rate and regularization alpha are selected using grid search with the search space determined with preliminary experiments so that the optimal solution is not too close to the boundaries. Batch size search space was $2^i$ for all $i$ from $1$ until $2^i$ was equal to the number of samples in the dataset. Learning rate search space was $10^i$ for all $i$ between $-1$ and $-4$ \improvement{Parempi tapa esittää, että batch size oli 2. potenssi välillä 2-n ja learning rate oli 10. potenssi välillä 0.1 - 0.0001}.

For practical 

\begin{table}[h]
    \centering
    \begin{tabular}{lll}
        \toprule
        Algorithm              & Loss    & Hyperparameters                  \\
        \midrule
        Linear regression      & squared & batch size, learning rate, alpha \\
        Logistic regression    & log     & batch size, learning rate, alpha \\
        Support Vector Machine & hinge   & batch size, learning rate, alpha \\
        \bottomrule
    \end{tabular}
    \caption{Summary of the algorithms}
    \label{table:algorithms}
\end{table}


