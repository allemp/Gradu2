\chapter{Introduction}

% Intro
Machine learning (ML) systems are widely adopted and many organizations successfully have ML models running in production.

\begin{itemize}
    \item Problem with MLOps/ML tools
        \begin{itemize}
            \item traditional ML performance metrics such as accuracy
            \item fancy features such as neural architecture search, AutoML, performance tuning
            \item fancy techniques such as early stopping, grid search, bayesian optimization search etc.
            \item little support for non-ML metrics: CPU util, memory used, latency, throughput (images/s etc.), hardware required (CPU, GPU, TPU etc.)
            \item ML in production has many objectives besides accuracy for example: satellite image processing model A took 4-5h and model B took 5min. Model A is infeasible in production despite being more accurate.
            \item "Better' depends on the specific application
        \end{itemize}
    \item Hypothesis: Early stopping will speed up computing non-ML metrics (CPU util, Memory use, GPU/TPU requirement, latency, throughput)
\end{itemize}

TODO smaller and smaller devices, limited resources

% Aim of the study
Real-world ML systems in addition to ML performance metrics will have similar performance metrics as traditional software systems. The aim of the study is to tune performance metrics particularly relevant to real-world ML systems. 



% Contribution
The main contribution of this master's thesis is using ML performance tuning techniques such as early stopping for tuning a wider range of real-world ML system performance metrics.