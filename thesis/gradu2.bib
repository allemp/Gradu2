@online{amodeiAICompute2018,
  title = {{{AI}} and Compute},
  author = {Amodei, Dario and Hernandez, Danny},
  date = {2018-05-16},
  url = {https://openai.com/research/ai-and-compute},
  urldate = {2023-07-29},
  abstract = {We’re releasing an analysis showing that since 2012, the amount of compute used in the largest AI training runs has been increasing exponentially with a 3.4-month doubling time (by comparison, Moore’s Law had a 2-year doubling period)[\^footnote-correction]. Since 2012, this metric has grown by more than 300,000x (a 2-year doubling period would yield only a 7x increase). Improvements in compute have been a key component of AI progress, so as long as this trend continues, it’s worth preparing for the implications of systems far outside today’s capabilities.},
  langid = {american},
  file = {/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/3XICH52X/ai-and-compute.html}
}

@online{bakerAcceleratingNeuralArchitecture2017,
  title = {Accelerating {{Neural Architecture Search}} Using {{Performance Prediction}}},
  author = {Baker, Bowen and Gupta, Otkrist and Raskar, Ramesh and Naik, Nikhil},
  date = {2017-11-08},
  eprint = {1705.10823},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1705.10823},
  url = {http://arxiv.org/abs/1705.10823},
  urldate = {2023-01-25},
  abstract = {Methods for neural network hyperparameter optimization and meta-modeling are computationally expensive due to the need to train a large number of model configurations. In this paper, we show that standard frequentist regression models can predict the final performance of partially trained model configurations using features based on network architectures, hyperparameters, and time-series validation performance data. We empirically show that our performance prediction models are much more effective than prominent Bayesian counterparts, are simpler to implement, and are faster to train. Our models can predict final performance in both visual classification and language modeling domains, are effective for predicting performance of drastically varying model architectures, and can even generalize between model classes. Using these prediction models, we also propose an early stopping method for hyperparameter optimization and meta-modeling, which obtains a speedup of a factor up to 6x in both hyperparameter optimization and meta-modeling. Finally, we empirically show that our early stopping method can be seamlessly incorporated into both reinforcement learning-based architecture selection algorithms and bandit based search methods. Through extensive experimentation, we empirically show our performance prediction models and early stopping algorithm are state-of-the-art in terms of prediction accuracy and speedup achieved while still identifying the optimal model configurations.},
  pubstate = {preprint},
  keywords = {\_tablet,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing},
  file = {/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/I93LMDHA/Baker et al_2017_Accelerating Neural Architecture Search using Performance Prediction.pdf;/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/IWHABXLB/1705.html}
}

@inproceedings{breckMLTestScore2017a,
  title = {The {{ML Test Score}}: {{A Rubric}} for {{ML Production Readiness}} and {{Technical Debt Reduction}}},
  shorttitle = {The {{ML Test Score}}},
  booktitle = {Proceedings of {{IEEE Big Data}}},
  author = {Breck, Eric and Cai, Shanqing and Nielsen, Eric and Salib, Michael and Sculley, D.},
  date = {2017},
  keywords = {\_tablet},
  file = {/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/LEKCIDWU/Breck et al_2017_The ML Test Score.pdf}
}

@online{brunnertPerformanceorientedDevOpsResearch2015,
  title = {Performance-Oriented {{DevOps}}: {{A Research Agenda}}},
  shorttitle = {Performance-Oriented {{DevOps}}},
  author = {Brunnert, Andreas and family=Hoorn, given=Andre, prefix=van, useprefix=true and Willnecker, Felix and Danciu, Alexandru and Hasselbring, Wilhelm and Heger, Christoph and Herbst, Nikolas and Jamshidi, Pooyan and Jung, Reiner and family=Kistowski, given=Joakim, prefix=von, useprefix=true and Koziolek, Anne and Kroß, Johannes and Spinner, Simon and Vögele, Christian and Walter, Jürgen and Wert, Alexander},
  date = {2015-08-18},
  eprint = {1508.04752},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1508.04752},
  url = {http://arxiv.org/abs/1508.04752},
  urldate = {2023-01-17},
  abstract = {DevOps is a trend towards a tighter integration between development (Dev) and operations (Ops) teams. The need for such an integration is driven by the requirement to continuously adapt enterprise applications (EAs) to changes in the business environment. As of today, DevOps concepts have been primarily introduced to ensure a constant flow of features and bug fixes into new releases from a functional perspective. In order to integrate a non-functional perspective into these DevOps concepts this report focuses on tools, activities, and processes to ensure one of the most important quality attributes of a software system, namely performance. Performance describes system properties concerning its timeliness and use of resources. Common metrics are response time, throughput, and resource utilization. Performance goals for EAs are typically defined by setting upper and/or lower bounds for these metrics and specific business transactions. In order to ensure that such performance goals can be met, several activities are required during development and operation of these systems as well as during the transition from Dev to Ops. Activities during development are typically summarized by the term Software Performance Engineering (SPE), whereas activities during operations are called Application Performance Management (APM). SPE and APM were historically tackled independently from each other, but the newly emerging DevOps concepts require and enable a tighter integration between both activity streams. This report presents existing solutions to support this integration as well as open research challenges in this area.},
  pubstate = {preprint},
  keywords = {Computer Science - Performance,Computer Science - Software Engineering},
  file = {/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/9MDJPVS9/Brunnert et al_2015_Performance-oriented DevOps.pdf;/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/3DKEU57U/1508.html}
}

@inproceedings{cardososilvaBenchmarkingMachineLearning2020,
  title = {Benchmarking {{Machine Learning Solutions}} in {{Production}}},
  booktitle = {2020 19th {{IEEE International Conference}} on {{Machine Learning}} and {{Applications}} ({{ICMLA}})},
  author = {Cardoso Silva, Lucas and Rezende Zagatti, Fernando and Silva Sette, Bruno and Nildaimon dos Santos Silva, Lucas and Lucrédio, Daniel and Furtado Silva, Diego and family=Medeiros Caseli, given=Helena, prefix=de, useprefix=true},
  date = {2020-12},
  pages = {626--633},
  doi = {10.1109/ICMLA51294.2020.00104},
  abstract = {Machine learning (ML) is becoming critical to many businesses. Keeping an ML solution online and responding is therefore a necessity, and is part of the MLOps (Machine Learning operationalization) movement. One aspect for this process is monitoring not only prediction quality, but also system resources. This is important to correctly provide the necessary infrastructure, either using a fully-managed cloud platform or a local solution. This is not a difficult task, as there are many tools available. However, it requires some planning and knowledge about what to monitor. Also, many ML professionals are not experts in system operations and may not have the skills to easily setup a monitoring and benchmarking environment. In the spirit of MLOps, this paper presents an approach, based on a simple API and set of tools, to monitor ML solutions. The approach was tested with 9 different solutions. The results indicate that the approach can deliver useful information to help in decision making, proper resource provision and operation of ML systems.},
  eventtitle = {2020 19th {{IEEE International Conference}} on {{Machine Learning}} and {{Applications}} ({{ICMLA}})},
  keywords = {\_tablet,Benchmark,Benchmark testing,Machine learning,Machine Learning,MLOps,Monitoring,Production,Systems operation,Task analysis,Tools},
  file = {/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/7WJUB6UG/Cardoso Silva et al_2020_Benchmarking Machine Learning Solutions in Production.pdf;/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/3PXPYX5A/9356298.html}
}

@article{chenDeepLearningEdge2019,
  title = {Deep {{Learning With Edge Computing}}: {{A Review}}},
  shorttitle = {Deep {{Learning With Edge Computing}}},
  author = {Chen, Jiasi and Ran, Xukan},
  date = {2019-08},
  journaltitle = {Proceedings of the IEEE},
  shortjournal = {Proc. IEEE},
  volume = {107},
  number = {8},
  pages = {1655--1674},
  issn = {0018-9219, 1558-2256},
  doi = {10.1109/JPROC.2019.2921977},
  url = {https://ieeexplore.ieee.org/document/8763885/},
  urldate = {2023-07-29},
  abstract = {Deep learning is currently widely used in a variety of applications, including computer vision and natural language processing. End devices such as smartphones and IoT sensors are generating data that need to be analyzed in real-time using deep learning or used to train deep learning models. However, deep learning inference and training require substantial computation resources to run quickly. Edge computing, where a fine mesh of compute nodes are placed close to end devices, is a viable way to meet the high computation and low latency requirements of deep learning on edge devices, and also provides additional benefits in terms of privacy, bandwidth efficiency, and scalability.},
  langid = {english},
  keywords = {\_tablet},
  file = {/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/H3RYTRQL/Chen_Ran_2019_Deep Learning With Edge Computing.pdf}
}

@online{coteQualityIssuesMachine2022,
  title = {Quality Issues in {{Machine Learning Software Systems}}},
  author = {Côté, Pierre-Olivier and Nikanjam, Amin and Bouchoucha, Rached and Khomh, Foutse},
  date = {2022-08-22},
  eprint = {2208.08982},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2208.08982},
  url = {http://arxiv.org/abs/2208.08982},
  urldate = {2022-12-07},
  abstract = {Context: An increasing demand is observed in various domains to employ Machine Learning (ML) for solving complex problems. ML models are implemented as software components and deployed in Machine Learning Software Systems (MLSSs). Problem: There is a strong need for ensuring the serving quality of MLSSs. False or poor decisions of such systems can lead to malfunction of other systems, significant financial losses, or even threat to human life. The quality assurance of MLSSs is considered as a challenging task and currently is a hot research topic. Moreover, it is important to cover all various aspects of the quality in MLSSs. Objective: This paper aims to investigate the characteristics of real quality issues in MLSSs from the viewpoint of practitioners. This empirical study aims to identify a catalog of bad-practices related to poor quality in MLSSs. Method: We plan to conduct a set of interviews with practitioners/experts, believing that interviews are the best method to retrieve their experience and practices when dealing with quality issues. We expect that the catalog of issues developed at this step will also help us later to identify the severity, root causes, and possible remedy for quality issues of MLSSs, allowing us to develop efficient quality assurance tools for ML models and MLSSs.},
  pubstate = {preprint},
  keywords = {\_tablet,Computer Science - Machine Learning,Computer Science - Software Engineering},
  file = {/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/NPNEQEVA/Côté et al_2022_Quality issues in Machine Learning Software Systems.pdf;/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/ES8GKMEI/2208.html}
}

@article{dengMNISTDatabaseHandwritten2012,
  title = {The {{MNIST Database}} of {{Handwritten Digit Images}} for {{Machine Learning Research}} [{{Best}} of the {{Web}}]},
  author = {Deng, Li},
  date = {2012-11},
  journaltitle = {IEEE Signal Processing Magazine},
  volume = {29},
  number = {6},
  pages = {141--142},
  issn = {1558-0792},
  doi = {10.1109/MSP.2012.2211477},
  abstract = {In this issue, “Best of the Web” presents the modified National Institute of Standards and Technology (MNIST) resources, consisting of a collection of handwritten digit images used extensively in optical character recognition and machine learning research.},
  eventtitle = {{{IEEE Signal Processing Magazine}}},
  keywords = {Machine learning},
  file = {/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/YD2EFMVK/Deng_2012_The MNIST Database of Handwritten Digit Images for Machine Learning Research.pdf;/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/8XXBPIR7/6296535.html}
}

@online{dodgeFineTuningPretrainedLanguage2020,
  title = {Fine-{{Tuning Pretrained Language Models}}: {{Weight Initializations}}, {{Data Orders}}, and {{Early Stopping}}},
  shorttitle = {Fine-{{Tuning Pretrained Language Models}}},
  author = {Dodge, Jesse and Ilharco, Gabriel and Schwartz, Roy and Farhadi, Ali and Hajishirzi, Hannaneh and Smith, Noah},
  date = {2020-02-14},
  eprint = {2002.06305},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2002.06305},
  url = {http://arxiv.org/abs/2002.06305},
  urldate = {2023-07-30},
  abstract = {Fine-tuning pretrained contextual word embedding models to supervised downstream tasks has become commonplace in natural language processing. This process, however, is often brittle: even with the same hyperparameter values, distinct random seeds can lead to substantially different results. To better understand this phenomenon, we experiment with four datasets from the GLUE benchmark, fine-tuning BERT hundreds of times on each while varying only the random seeds. We find substantial performance increases compared to previously reported results, and we quantify how the performance of the best-found model varies as a function of the number of fine-tuning trials. Further, we examine two factors influenced by the choice of random seed: weight initialization and training data order. We find that both contribute comparably to the variance of out-of-sample performance, and that some weight initializations perform well across all tasks explored. On small datasets, we observe that many fine-tuning trials diverge part of the way through training, and we offer best practices for practitioners to stop training less promising runs early. We publicly release all of our experimental data, including training and validation scores for 2,100 trials, to encourage further analysis of training dynamics during fine-tuning.},
  pubstate = {preprint},
  keywords = {\_tablet,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/KZLYZF2C/Dodge et al_2020_Fine-Tuning Pretrained Language Models.pdf;/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/BNDUS4FB/2002.html}
}

@article{domingosFewUsefulThings2012,
  title = {A Few Useful Things to Know about Machine Learning},
  author = {Domingos, Pedro},
  date = {2012-10-01},
  journaltitle = {Communications of the ACM},
  shortjournal = {Commun. ACM},
  volume = {55},
  number = {10},
  pages = {78--87},
  issn = {0001-0782},
  doi = {10.1145/2347736.2347755},
  url = {https://doi.org/10.1145/2347736.2347755},
  urldate = {2023-03-14},
  abstract = {Tapping into the "folk knowledge" needed to advance machine learning applications.},
  file = {/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/J2LSZY59/Domingos_2012_A few useful things to know about machine learning.pdf}
}

@inproceedings{eistySurveySoftwareMetric2018,
  title = {A {{Survey}} of {{Software Metric Use}} in {{Research Software Development}}},
  booktitle = {2018 {{IEEE}} 14th {{International Conference}} on E-{{Science}} (e-{{Science}})},
  author = {Eisty, Nasir U. and Thiruvathukal, George K. and Carver, Jeffrey C.},
  date = {2018-10},
  pages = {212--222},
  doi = {10.1109/eScience.2018.00036},
  abstract = {Background: Breakthroughs in research increasingly depend on complex software libraries, tools, and applications aimed at supporting specific science, engineering, business, or humanities disciplines. The complexity and criticality of this software motivate the need for ensuring quality and reliability. Software metrics are a key tool for assessing, measuring, and understanding software quality and reliability. Aims: The goal of this work is to better understand how research software developers use traditional software engineering concepts, like metrics, to support and evaluate both the software and the software development process. One key aspect of this goal is to identify how the set of metrics relevant to research software corresponds to the metrics commonly used in traditional software engineering. Method: We surveyed research software developers to gather information about their knowledge and use of code metrics and software process metrics. We also analyzed the influence of demographics (project size, development role, and development stage) on these metrics. Results: The survey results, from 129 respondents, indicate that respondents have a general knowledge of metrics. However, their knowledge of specific SE metrics is lacking, their use even more limited. The most used metrics relate to performance and testing. Even though code complexity often poses a significant challenge to research software development, respondents did not indicate much use of code metrics. Conclusions: Research software developers appear to be interested and see some value in software metrics but may be encountering roadblocks when trying to use them. Further study is needed to determine the extent to which these metrics could provide value in continuous process improvement.},
  eventtitle = {2018 {{IEEE}} 14th {{International Conference}} on E-{{Science}} (e-{{Science}})},
  keywords = {Complexity theory,Software,Software engineering,Software metrics,{Survey, Software Metrics, Software Engineering, Research Software},Tools},
  file = {/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/9BLC6WCD/Eisty et al_2018_A Survey of Software Metric Use in Research Software Development.pdf;/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/QQIXAFZM/8588655.html}
}

@inproceedings{fayyadKnowledgeDiscoveryData1996,
  title = {Knowledge {{Discovery}} and {{Data Mining}}: {{Towards}} a {{Unifying Framework}}},
  booktitle = {{{KDD-96 Proceedings}}},
  author = {Fayyad, Usama and Piatetsky-Shapiro, Gregory and Smyth, Padhraic},
  date = {1996},
  pages = {7},
  abstract = {This paper presents a first step towards a unifying frameworkfor KnowledgeDiscovery in Databases. We describe finks betweendata milfing, knowledgediscovery, and other related fields. Wethen define the KDDprocess and basic data mining algorithms, discuss application issues and conclude with an analysis of challengesfacing practitioners in the field.},
  eventtitle = {{{KDD-96}}},
  langid = {english},
  file = {C\:\\Users\\master\\Zotero\\storage\\6RPQKHQ5\\Fayyad et al_Knowledge Discovery and Data Mining_annotated.pdf;C\:\\Users\\master\\Zotero\\storage\\QAFSNS2S\\Fayyad et al_Knowledge Discovery and Data Mining.pdf}
}

@article{fernandez-lozanoMethodologyDesignExperiments2016,
  title = {A Methodology for the Design of Experiments in Computational Intelligence with Multiple Regression Models},
  author = {Fernandez-Lozano, Carlos and Gestal, Marcos and Munteanu, Cristian R. and Dorado, Julian and Pazos, Alejandro},
  date = {2016-12-01},
  journaltitle = {PeerJ},
  shortjournal = {PeerJ},
  volume = {4},
  eprint = {27920952},
  eprinttype = {pmid},
  pages = {e2721},
  issn = {2167-8359},
  doi = {10.7717/peerj.2721},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5136129/},
  urldate = {2023-02-15},
  abstract = {The design of experiments and the validation of the results achieved with them are vital in any research study. This paper focuses on the use of different Machine Learning approaches for regression tasks in the field of Computational Intelligence and especially on a correct comparison between the different results provided for different methods, as those techniques are complex systems that require further study to be fully understood. A methodology commonly accepted in Computational intelligence is implemented in an R package called RRegrs. This package includes ten simple and complex regression models to carry out predictive modeling using Machine Learning and well-known regression algorithms. The framework for experimental design presented herein is evaluated and validated against RRegrs. Our results are different for three out of five state-of-the-art simple datasets and it can be stated that the selection of the best model according to our proposal is statistically significant and relevant. It is of relevance to use a statistical approach to indicate whether the differences are statistically significant using this kind of algorithms. Furthermore, our results with three real complex datasets report different best models than with the previously published methodology. Our final goal is to provide a complete methodology for the use of different steps in order to compare the results obtained in Computational Intelligence problems, as well as from other fields, such as for bioinformatics, cheminformatics, etc., given that our proposal is open and~modifiable.},
  pmcid = {PMC5136129},
  file = {/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/R4QQLYJX/Fernandez-Lozano et al_2016_A methodology for the design of experiments in computational intelligence with.pdf}
}

@article{finzerDataScienceEducation2013,
  title = {The {{Data Science Education Dilemma}}},
  author = {Finzer, William},
  date = {2013},
  journaltitle = {Technology Innovations in Statistics Education},
  volume = {7},
  number = {2},
  doi = {10.5070/T572013891},
  url = {https://escholarship.org/uc/item/7gv0q9dc},
  urldate = {2023-01-17},
  abstract = {The need for people fluent in working with data is growing rapidly and enormously, but U.S. K–12 education does not provide meaningful learning experiences designed to develop understanding of data science concepts or a fluency with data science skills. Data science is inherently inter-disciplinary, so it makes sense to integrate it with existing content areas, but difficulties abound. Consideration of the work involved in doing data science and the habits of mind that lie behind it leads to a way of thinking about integrating data science with mathematics and science. Examples drawn from current activity development in the Data Games project shed some light on what technology-based, data-driven might be like. The project’s ongoing research on learners’ conceptions of organizing data and the relevance to data science education is explained.},
  langid = {english},
  keywords = {\_tablet},
  file = {/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/YWX2L6LE/Finzer_2013_The Data Science Education Dilemma.pdf}
}

@online{hestnessDeepLearningScaling2017,
  title = {Deep {{Learning Scaling}} Is {{Predictable}}, {{Empirically}}},
  author = {Hestness, Joel and Narang, Sharan and Ardalani, Newsha and Diamos, Gregory and Jun, Heewoo and Kianinejad, Hassan and Patwary, Md Mostofa Ali and Yang, Yang and Zhou, Yanqi},
  date = {2017-12-01},
  eprint = {1712.00409},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/1712.00409},
  urldate = {2023-07-29},
  abstract = {Deep learning (DL) creates impactful advances following a virtuous recipe: model architecture search, creating large training data sets, and scaling computation. It is widely believed that growing training sets and models should improve accuracy and result in better products. As DL application domains grow, we would like a deeper understanding of the relationships between training set size, computational scale, and model accuracy improvements to advance the state-of-the-art.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/Z3LL9RNB/Hestness et al_2017_Deep Learning Scaling is Predictable, Empirically.pdf}
}

@online{hintonDistillingKnowledgeNeural2015,
  title = {Distilling the {{Knowledge}} in a {{Neural Network}}},
  author = {Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  date = {2015-03-09},
  eprint = {1503.02531},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1503.02531},
  url = {http://arxiv.org/abs/1503.02531},
  urldate = {2023-02-03},
  abstract = {A very simple way to improve the performance of almost any machine learning algorithm is to train many different models on the same data and then to average their predictions. Unfortunately, making predictions using a whole ensemble of models is cumbersome and may be too computationally expensive to allow deployment to a large number of users, especially if the individual models are large neural nets. Caruana and his collaborators have shown that it is possible to compress the knowledge in an ensemble into a single model which is much easier to deploy and we develop this approach further using a different compression technique. We achieve some surprising results on MNIST and we show that we can significantly improve the acoustic model of a heavily used commercial system by distilling the knowledge in an ensemble of models into a single model. We also introduce a new type of ensemble composed of one or more full models and many specialist models which learn to distinguish fine-grained classes that the full models confuse. Unlike a mixture of experts, these specialist models can be trained rapidly and in parallel.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning},
  file = {/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/K9JTAWDA/Hinton et al_2015_Distilling the Knowledge in a Neural Network.pdf;/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/JENB6RVC/1503.html}
}

@online{hofferTrainLongerGeneralize2018,
  title = {Train Longer, Generalize Better: Closing the Generalization Gap in Large Batch Training of Neural Networks},
  shorttitle = {Train Longer, Generalize Better},
  author = {Hoffer, Elad and Hubara, Itay and Soudry, Daniel},
  date = {2018-01-01},
  eprint = {1705.08741},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1705.08741},
  url = {http://arxiv.org/abs/1705.08741},
  urldate = {2023-08-02},
  abstract = {Background: Deep learning models are typically trained using stochastic gradient descent or one of its variants. These methods update the weights using their gradient, estimated from a small fraction of the training data. It has been observed that when using large batch sizes there is a persistent degradation in generalization performance - known as the "generalization gap" phenomena. Identifying the origin of this gap and closing it had remained an open problem. Contributions: We examine the initial high learning rate training phase. We find that the weight distance from its initialization grows logarithmically with the number of weight updates. We therefore propose a "random walk on random landscape" statistical model which is known to exhibit similar "ultra-slow" diffusion behavior. Following this hypothesis we conducted experiments to show empirically that the "generalization gap" stems from the relatively small number of updates rather than the batch size, and can be completely eliminated by adapting the training regime used. We further investigate different techniques to train models in the large-batch regime and present a novel algorithm named "Ghost Batch Normalization" which enables significant decrease in the generalization gap without increasing the number of updates. To validate our findings we conduct several additional experiments on MNIST, CIFAR-10, CIFAR-100 and ImageNet. Finally, we reassess common practices and beliefs concerning training of deep models and suggest they may not be optimal to achieve good generalization.},
  pubstate = {preprint},
  keywords = {\_tablet,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/CT97GYUN/Hoffer et al_2018_Train longer, generalize better.pdf;/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/9Q9H65Q6/1705.html}
}

@online{imbreaAutomatedMachineLearning2021,
  title = {Automated {{Machine Learning Techniques}} for {{Data Streams}}},
  author = {Imbrea, Alexandru-Ionut},
  date = {2021-06-14},
  eprint = {2106.07317},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2106.07317},
  url = {http://arxiv.org/abs/2106.07317},
  urldate = {2023-01-25},
  abstract = {Automated machine learning techniques benefited from tremendous research progress in recently. These developments and the continuous-growing demand for machine learning experts led to the development of numerous AutoML tools. However, these tools assume that the entire training dataset is available upfront and that the underlying distribution does not change over time. These assumptions do not hold in a data stream mining setting where an unbounded stream of data cannot be stored and is likely to manifest concept drift. Industry applications of machine learning on streaming data become more popular due to the increasing adoption of real-time streaming patterns in IoT, microservices architectures, web analytics, and other fields. The research summarized in this paper surveys the state-of-the-art open-source AutoML tools, applies them to data collected from streams, and measures how their performance changes over time. For comparative purposes, batch, batch incremental and instance incremental estimators are applied and compared. Moreover, a meta-learning technique for online algorithm selection based on meta-feature extraction is proposed and compared while model replacement and continual AutoML techniques are discussed. The results show that off-the-shelf AutoML tools can provide satisfactory results but in the presence of concept drift, detection or adaptation techniques have to be applied to maintain the predictive accuracy over time.},
  pubstate = {preprint},
  keywords = {\_tablet,Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/PWERNVYQ/Imbrea_2021_Automated Machine Learning Techniques for Data Streams.pdf;/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/ER4UAF2R/2106.html}
}

@article{kreuzbergerMachineLearningOperations2023,
  title = {Machine {{Learning Operations}} ({{MLOps}}): {{Overview}}, {{Definition}}, and {{Architecture}}},
  shorttitle = {Machine {{Learning Operations}} ({{MLOps}})},
  author = {Kreuzberger, Dominik and Kühl, Niklas and Hirschl, Sebastian},
  date = {2023},
  journaltitle = {IEEE Access},
  volume = {11},
  pages = {31866--31879},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2023.3262138},
  abstract = {The final goal of all industrial machine learning (ML) projects is to develop ML products and rapidly bring them into production. However, it is highly challenging to automate and operationalize ML products and thus many ML endeavors fail to deliver on their expectations. The paradigm of Machine Learning Operations (MLOps) addresses this issue. MLOps includes several aspects, such as best practices, sets of concepts, and development culture. However, MLOps is still a vague term and its consequences for researchers and professionals are ambiguous. To address this gap, we conduct mixed-method research, including a literature review, a tool review, and expert interviews. As a result of these investigations, we contribute to the body of knowledge by providing an aggregated overview of the necessary principles, components, and roles, as well as the associated architecture and workflows. Furthermore, we provide a comprehensive definition of MLOps and highlight open challenges in the field. Finally, this work provides guidance for ML researchers and practitioners who want to automate and operate their ML products with a designated set of technologies.},
  eventtitle = {{{IEEE Access}}},
  keywords = {Automation,Bibliographies,CI/CD,Codes,Collaboration,DevOps,Interviews,machine learning,Machine learning,MLOps,operations,Training,workflow orchestration},
  file = {/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/EJZL4WQN/Kreuzberger et al_2023_Machine Learning Operations (MLOps).pdf;/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/QTB7H5IF/10081336.html}
}

@inproceedings{kumarResourceefficientMachineLearning2017,
  title = {Resource-Efficient Machine Learning in 2 {{KB RAM}} for the Internet of Things},
  booktitle = {Proceedings of the 34th {{International Conference}} on {{Machine Learning}} - {{Volume}} 70},
  author = {Kumar, Ashish and Goyal, Saurabh and Varma, Manik},
  date = {2017-08-06},
  series = {{{ICML}}'17},
  pages = {1935--1944},
  publisher = {{JMLR.org}},
  location = {{Sydney, NSW, Australia}},
  abstract = {This paper develops a novel tree-based algorithm, called Bonsai, for efficient prediction on IoT devices - such as those based on the Arduino Uno board having an 8 bit ATmega328P microcontroller operating at 16 MHz with no native floating point support, 2 KB RAM and 32 KB read-only flash. Bonsai maintains prediction accuracy while minimizing model size and prediction costs by: (a) developing a tree model which learns a single, shallow, sparse tree with powerful nodes; (b) sparsely projecting all data into a low-dimensional space in which the tree is learnt; and (c) jointly learning all tree and projection parameters. Experimental results on multiple benchmark datasets demonstrate that Bonsai can make predictions in milliseconds even on slow microcontrollers, can fit in KB of memory, has lower battery consumption than all other algorithms while achieving prediction accuracies that can be as much as 30\% higher than state-of-the-art methods for resource-efficient machine learning. Bonsai is also shown to generalize to other resource constrained settings beyond IoT by generating significantly better search results as compared to Bing's L3 ranker when the model size is restricted to 300 bytes. Bonsai's code can be downloaded from (BonsaiCode).},
  keywords = {\_tablet},
  file = {/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/DTSA6WCD/Kumar et al_2017_Resource-efficient machine learning in 2 KB RAM for the internet of things.pdf}
}

@online{leBuildingHighlevelFeatures2012,
  title = {Building High-Level Features Using Large Scale Unsupervised Learning},
  author = {Le, Quoc V. and Ranzato, Marc'Aurelio and Monga, Rajat and Devin, Matthieu and Chen, Kai and Corrado, Greg S. and Dean, Jeff and Ng, Andrew Y.},
  date = {2012-07-12},
  eprint = {1112.6209},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1112.6209},
  url = {http://arxiv.org/abs/1112.6209},
  urldate = {2023-02-03},
  abstract = {We consider the problem of building high-level, class-specific feature detectors from only unlabeled data. For example, is it possible to learn a face detector using only unlabeled images? To answer this, we train a 9-layered locally connected sparse autoencoder with pooling and local contrast normalization on a large dataset of images (the model has 1 billion connections, the dataset has 10 million 200x200 pixel images downloaded from the Internet). We train this network using model parallelism and asynchronous SGD on a cluster with 1,000 machines (16,000 cores) for three days. Contrary to what appears to be a widely-held intuition, our experimental results reveal that it is possible to train a face detector without having to label images as containing a face or not. Control experiments show that this feature detector is robust not only to translation but also to scaling and out-of-plane rotation. We also find that the same network is sensitive to other high-level concepts such as cat faces and human bodies. Starting with these learned features, we trained our network to obtain 15.8\% accuracy in recognizing 20,000 object categories from ImageNet, a leap of 70\% relative improvement over the previous state-of-the-art.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning},
  file = {/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/HA2RAJ2C/Le et al_2012_Building high-level features using large scale unsupervised learning.pdf;/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/7CYMMR8Y/1112.html}
}

@article{lecunDeepLearning2015,
  title = {Deep Learning},
  author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  date = {2015-05},
  journaltitle = {Nature},
  volume = {521},
  number = {7553},
  pages = {436--444},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/nature14539},
  url = {https://www.nature.com/articles/nature14539},
  urldate = {2023-06-15},
  abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
  issue = {7553},
  langid = {english},
  keywords = {Computer science,Mathematics and computing},
  file = {/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/Z4NV27YU/LeCun et al_2015_Deep learning.pdf}
}

@online{liawTuneResearchPlatform2018,
  title = {Tune: {{A Research Platform}} for {{Distributed Model Selection}} and {{Training}}},
  shorttitle = {Tune},
  author = {Liaw, Richard and Liang, Eric and Nishihara, Robert and Moritz, Philipp and Gonzalez, Joseph E. and Stoica, Ion},
  date = {2018-07-13},
  eprint = {1807.05118},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1807.05118},
  url = {http://arxiv.org/abs/1807.05118},
  urldate = {2023-02-22},
  abstract = {Modern machine learning algorithms are increasingly computationally demanding, requiring specialized hardware and distributed computation to achieve high performance in a reasonable time frame. Many hyperparameter search algorithms have been proposed for improving the efficiency of model selection, however their adaptation to the distributed compute environment is often ad-hoc. We propose Tune, a unified framework for model selection and training that provides a narrow-waist interface between training scripts and search algorithms. We show that this interface meets the requirements for a broad range of hyperparameter search algorithms, allows straightforward scaling of search to large clusters, and simplifies algorithm implementation. We demonstrate the implementation of several state-of-the-art hyperparameter search algorithms in Tune. Tune is available at http://ray.readthedocs.io/en/latest/tune.html.},
  pubstate = {preprint},
  keywords = {\_tablet,{Computer Science - Distributed, Parallel, and Cluster Computing},Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/CZZSUU97/Liaw et al_2018_Tune.pdf;/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/V45V3LPN/1807.html}
}

@online{liHyperbandNovelBanditBased2018,
  title = {Hyperband: {{A Novel Bandit-Based Approach}} to {{Hyperparameter Optimization}}},
  shorttitle = {Hyperband},
  author = {Li, Lisha and Jamieson, Kevin and DeSalvo, Giulia and Rostamizadeh, Afshin and Talwalkar, Ameet},
  date = {2018-06-18},
  eprint = {1603.06560},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1603.06560},
  url = {http://arxiv.org/abs/1603.06560},
  urldate = {2023-08-03},
  abstract = {Performance of machine learning algorithms depends critically on identifying a good set of hyperparameters. While recent approaches use Bayesian optimization to adaptively select configurations, we focus on speeding up random search through adaptive resource allocation and early-stopping. We formulate hyperparameter optimization as a pure-exploration non-stochastic infinite-armed bandit problem where a predefined resource like iterations, data samples, or features is allocated to randomly sampled configurations. We introduce a novel algorithm, Hyperband, for this framework and analyze its theoretical properties, providing several desirable guarantees. Furthermore, we compare Hyperband with popular Bayesian optimization methods on a suite of hyperparameter optimization problems. We observe that Hyperband can provide over an order-of-magnitude speedup over our competitor set on a variety of deep-learning and kernel-based learning problems.},
  pubstate = {preprint},
  keywords = {\_tablet,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/SN4XNI9W/Li et al_2018_Hyperband.pdf;/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/TMDUQ4T5/1603.html}
}

@online{liSystemMassivelyParallel2020,
  title = {A {{System}} for {{Massively Parallel Hyperparameter Tuning}}},
  author = {Li, Liam and Jamieson, Kevin and Rostamizadeh, Afshin and Gonina, Ekaterina and Hardt, Moritz and Recht, Benjamin and Talwalkar, Ameet},
  date = {2020-03-15},
  eprint = {1810.05934},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1810.05934},
  url = {http://arxiv.org/abs/1810.05934},
  urldate = {2023-08-03},
  abstract = {Modern learning models are characterized by large hyperparameter spaces and long training times. These properties, coupled with the rise of parallel computing and the growing demand to productionize machine learning workloads, motivate the need to develop mature hyperparameter optimization functionality in distributed computing settings. We address this challenge by first introducing a simple and robust hyperparameter optimization algorithm called ASHA, which exploits parallelism and aggressive early-stopping to tackle large-scale hyperparameter optimization problems. Our extensive empirical results show that ASHA outperforms existing state-of-the-art hyperparameter optimization methods; scales linearly with the number of workers in distributed settings; and is suitable for massive parallelism, as demonstrated on a task with 500 workers. We then describe several design decisions we encountered, along with our associated solutions, when integrating ASHA in Determined AI's end-to-end production-quality machine learning system that offers hyperparameter tuning as a service.},
  pubstate = {preprint},
  keywords = {\_tablet,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/BZGNEU25/Li et al_2020_A System for Massively Parallel Hyperparameter Tuning.pdf;/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/H3WBUUSG/1810.html}
}

@online{lonesHowAvoidMachine2022,
  title = {How to Avoid Machine Learning Pitfalls: A Guide for Academic Researchers},
  shorttitle = {How to Avoid Machine Learning Pitfalls},
  author = {Lones, Michael A.},
  date = {2022-09-06},
  eprint = {2108.02497},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2108.02497},
  url = {http://arxiv.org/abs/2108.02497},
  urldate = {2022-12-07},
  abstract = {This document gives a concise outline of some of the common mistakes that occur when using machine learning techniques, and what can be done to avoid them. It is intended primarily as a guide for research students, and focuses on issues that are of particular concern within academic research, such as the need to do rigorous comparisons and reach valid conclusions. It covers five stages of the machine learning process: what to do before model building, how to reliably build models, how to robustly evaluate models, how to compare models fairly, and how to report results.},
  pubstate = {preprint},
  keywords = {\_tablet,Computer Science - Machine Learning},
  file = {/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/278JM9KT/Lones_2022_How to avoid machine learning pitfalls.pdf;/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/6RWMHTU8/2108.html}
}

@online{luoNeuralArchitectureOptimization2019,
  title = {Neural {{Architecture Optimization}}},
  author = {Luo, Renqian and Tian, Fei and Qin, Tao and Chen, Enhong and Liu, Tie-Yan},
  date = {2019-09-04},
  eprint = {1808.07233},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1808.07233},
  url = {http://arxiv.org/abs/1808.07233},
  urldate = {2023-01-25},
  abstract = {Automatic neural architecture design has shown its potential in discovering powerful neural network architectures. Existing methods, no matter based on reinforcement learning or evolutionary algorithms (EA), conduct architecture search in a discrete space, which is highly inefficient. In this paper, we propose a simple and efficient method to automatic neural architecture design based on continuous optimization. We call this new approach neural architecture optimization (NAO). There are three key components in our proposed approach: (1) An encoder embeds/maps neural network architectures into a continuous space. (2) A predictor takes the continuous representation of a network as input and predicts its accuracy. (3) A decoder maps a continuous representation of a network back to its architecture. The performance predictor and the encoder enable us to perform gradient based optimization in the continuous space to find the embedding of a new architecture with potentially better accuracy. Such a better embedding is then decoded to a network by the decoder. Experiments show that the architecture discovered by our method is very competitive for image classification task on CIFAR-10 and language modeling task on PTB, outperforming or on par with the best results of previous architecture search methods with a significantly reduction of computational resources. Specifically we obtain 1.93\% test set error rate for CIFAR-10 image classification task and 56.0 test set perplexity of PTB language modeling task. Furthermore, combined with the recent proposed weight sharing mechanism, we discover powerful architecture on CIFAR-10 (with error rate 2.93\%) and on PTB (with test set perplexity 56.6), with very limited computational resources (less than 10 GPU hours) for both tasks.},
  pubstate = {preprint},
  keywords = {\_tablet,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/6K6PGBVJ/Luo et al_2019_Neural Architecture Optimization.pdf;/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/KCLHHPPH/1808.html}
}

@online{maclaurinGradientbasedHyperparameterOptimization2015,
  title = {Gradient-Based {{Hyperparameter Optimization}} through {{Reversible Learning}}},
  author = {Maclaurin, Dougal and Duvenaud, David and Adams, Ryan P.},
  date = {2015-04-02},
  eprint = {1502.03492},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1502.03492},
  url = {http://arxiv.org/abs/1502.03492},
  urldate = {2023-02-03},
  abstract = {Tuning hyperparameters of learning algorithms is hard because gradients are usually unavailable. We compute exact gradients of cross-validation performance with respect to all hyperparameters by chaining derivatives backwards through the entire training procedure. These gradients allow us to optimize thousands of hyperparameters, including step-size and momentum schedules, weight initialization distributions, richly parameterized regularization schemes, and neural network architectures. We compute hyperparameter gradients by exactly reversing the dynamics of stochastic gradient descent with momentum.},
  pubstate = {preprint},
  keywords = {\_tablet,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/IXIGPQTZ/Maclaurin et al_2015_Gradient-based Hyperparameter Optimization through Reversible Learning.pdf;/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/RTHEZPGN/1502.html}
}

@article{mishraDevOpsSoftwareQuality2020,
  title = {{{DevOps}} and Software Quality: {{A}} Systematic Mapping},
  shorttitle = {{{DevOps}} and Software Quality},
  author = {Mishra, Alok and Otaiwi, Ziadoon},
  date = {2020-11-01},
  journaltitle = {Computer Science Review},
  shortjournal = {Computer Science Review},
  volume = {38},
  pages = {100308},
  issn = {1574-0137},
  doi = {10.1016/j.cosrev.2020.100308},
  url = {https://www.sciencedirect.com/science/article/pii/S1574013720304081},
  urldate = {2023-01-17},
  abstract = {Quality pressure is one of the factors affecting processes for software development in its various stages. DevOps is one of the proposed solutions to such pressure. The primary focus of DevOps is to increase the deployment speed, frequency and quality. DevOps is a mixture of different developments and operations to its multitudinous ramifications in software development industries, DevOps have attracted the interest of many researchers. There are considerable literature surveys on this critical innovation in software development, yet, little attention has been given to DevOps impact on software quality. This research is aimed at analyzing the implications of DevOps features on software quality. DevOps can also be referred to a change in organization cultures aimed at removal of gaps between the development and operations of an organization. The adoption of DevOps in an organization provides many benefits including quality but also brings challenges to an organization. This study presents systematic mapping of the impact of DevOps on software quality. The results of this study provide a better understanding of DevOps on software quality for both professionals and researchers working in this area. The study shows research was mainly focused in automation, culture, continuous delivery, fast feedback of DevOps. There is need of further research in many areas of DevOps (for instance: measurement, development of metrics of different stages to assess its performance, culture, practices toward ensuring quality assurance, and quality factors such as usability, efficiency, software maintainability and portability).},
  langid = {english},
  keywords = {Automation,Development,DevOps,Measurement,Operations,Software,Software quality,Systematic mapping},
  file = {/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/FI2BPQCJ/Mishra_Otaiwi_2020_DevOps and software quality.pdf;/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/NTDWUG9S/S1574013720304081.html}
}

@article{myllyahoMisbehaviourFaultTolerance2022,
  title = {On Misbehaviour and Fault Tolerance in Machine Learning Systems},
  author = {Myllyaho, Lalli and Raatikainen, Mikko and Männistö, Tomi and Nurminen, Jukka K. and Mikkonen, Tommi},
  date = {2022-01-01},
  journaltitle = {Journal of Systems and Software},
  shortjournal = {Journal of Systems and Software},
  volume = {183},
  pages = {111096},
  issn = {0164-1212},
  doi = {10.1016/j.jss.2021.111096},
  url = {https://www.sciencedirect.com/science/article/pii/S016412122100193X},
  urldate = {2023-02-03},
  abstract = {Machine learning (ML) provides us with numerous opportunities, allowing ML systems to adapt to new situations and contexts. At the same time, this adaptability raises uncertainties concerning the run-time product quality or dependability, such as reliability and security, of these systems. Systems can be tested and monitored, but this does not provide protection against faults and failures in adapted ML systems themselves. We studied software designs that aim at introducing fault tolerance in ML systems so that possible problems in ML components of the systems can be avoided. The research was conducted as a case study, and its data was collected through five semi-structured interviews with experienced software architects. We present a conceptualisation of the misbehaviour of ML systems, the perceived role of fault tolerance, and the designs used. Common patterns to incorporating ML components in design in a fault tolerant fashion have started to emerge. ML models are, for example, guarded by monitoring the inputs and their distribution, and enforcing business rules on acceptable outputs. Multiple, specialised ML models are used to adapt to the variations and changes in the surrounding world, and simpler fall-over techniques like default outputs are put in place to have systems up and running in the face of problems. However, the general role of these patterns is not widely acknowledged. This is mainly due to the relative immaturity of using ML as part of a complete software system: the field still lacks established frameworks and practices beyond training to implement, operate, and maintain the software that utilises ML. ML software engineering needs further analysis and development on all fronts.},
  langid = {english},
  keywords = {\_tablet,Case study,Fault tolerance,Machine learning,Software architecture,Software engineering},
  file = {/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/PF8PE5AX/Myllyaho et al_2022_On misbehaviour and fault tolerance in machine learning systems.pdf;/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/IRCSGYBT/S016412122100193X.html}
}

@article{olsonPMLBLargeBenchmark2017,
  title = {{{PMLB}}: A Large Benchmark Suite for Machine Learning Evaluation and Comparison},
  shorttitle = {{{PMLB}}},
  author = {Olson, Randal S. and La Cava, William and Orzechowski, Patryk and Urbanowicz, Ryan J. and Moore, Jason H.},
  date = {2017-12-11},
  journaltitle = {BioData Mining},
  shortjournal = {BioData Mining},
  volume = {10},
  number = {1},
  pages = {36},
  issn = {1756-0381},
  doi = {10.1186/s13040-017-0154-4},
  url = {https://doi.org/10.1186/s13040-017-0154-4},
  urldate = {2023-02-22},
  abstract = {The selection, development, or comparison of machine learning methods in data mining can be a difficult task based on the target problem and goals of a particular study. Numerous publicly available real-world and simulated benchmark datasets have emerged from different sources, but their organization and adoption as standards have been inconsistent. As such, selecting and curating specific benchmarks remains an unnecessary burden on machine learning practitioners and data scientists.},
  keywords = {Benchmarking,Data repository,Machine learning,Model evaluation},
  file = {/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/DQMHLZIA/Olson et al_2017_PMLB.pdf;/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/T9Y2UVYZ/s13040-017-0154-4.html}
}

@online{openaiIntroducingChatGPT2022,
  title = {Introducing {{ChatGPT}}},
  author = {OpenAI},
  date = {2022-11-30},
  url = {https://openai.com/blog/chatgpt},
  urldate = {2023-07-24},
  abstract = {We’ve trained a model called ChatGPT which interacts in a conversational way. The dialogue format makes it possible for ChatGPT to answer followup questions, admit its mistakes, challenge incorrect premises, and reject inappropriate requests.},
  langid = {american},
  file = {/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/6X4N5BY7/chatgpt.html}
}

@inproceedings{pereraImproveSoftwareQuality2017,
  title = {Improve Software Quality through Practicing {{DevOps}}},
  booktitle = {2017 {{Seventeenth International Conference}} on {{Advances}} in {{ICT}} for {{Emerging Regions}} ({{ICTer}})},
  author = {Perera, Pulasthi and Silva, Roshali and Perera, Indika},
  date = {2017-09},
  pages = {1--6},
  issn = {2472-7598},
  doi = {10.1109/ICTER.2017.8257807},
  abstract = {DevOps is extended from certain agile practices with a mix of patterns intended to improve collaboration between development and operation teams. The main purpose of this paper is to conduct a study on how DevOps practice has impacted to software quality. The secondary objective is to find how to improve quality efficiently. A literature survey has carried out to explore about current DevOps practices in industry. According to the literature survey, the conceptual research model was developed and five hypotheses were derived. Research objectives were accomplished by testing hypotheses using Pearson correlation. A linear model is derived based on the linear regression analysis. An online questionnaire was used to collect quantitative data whereas interviews with experts on DevOps and Quality assurance have been used to identify how to improve the quality of software by practicing DevOps. Recommendations are given based on interview feedback, hypotheses testing with regression analysis. According to the quantitative study, researchers have identified that quality of the software gets improved when practice DevOps by following CAMS (Culture, Automation, Measurement, Sharing) framework. Automation is the most critical factor to improve the software quality. As per the results of multiple regression analysis, it has proved culture, automation, measurement and sharing are important factors to consider to improve quality of the software. In conclusion it can be recommended to use DevOps to achieve high quality software.},
  eventtitle = {2017 {{Seventeenth International Conference}} on {{Advances}} in {{ICT}} for {{Emerging Regions}} ({{ICTer}})},
  keywords = {Automation,CAMS Framework,Companies,DevOps,ISO 9126,Quality,Software measurement,Software quality,Testing},
  file = {/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/D8E3C6NR/Perera et al_2017_Improve software quality through practicing DevOps.pdf;/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/URNWQ29A/8257807.html}
}

@article{posoldovaMachineLearningPipelines2020,
  title = {Machine {{Learning Pipelines}}: {{From Research}} to {{Production}}},
  shorttitle = {Machine {{Learning Pipelines}}},
  author = {Posoldova, Alexandra},
  date = {2020-11},
  journaltitle = {IEEE Potentials},
  volume = {39},
  number = {6},
  pages = {38--42},
  issn = {1558-1772},
  doi = {10.1109/MPOT.2020.3016280},
  abstract = {Machine learning (ML) and artificial intelligence (AI) are getting lot of attention these days, and an increasing number of people are interested in becoming data scientists. Many imagine ML/AI as a black box that does its magic and is somehow able to make predictions. Well, the magic is that an ML algorithm is designed in such a way that it is able to find a pattern in data that have the correct answers and use that to predict the next answer. The learning task may vary from predicting the next word in a sentence, a sentiment, or what else would you like to buy based on what you already have in your basket.},
  eventtitle = {{{IEEE Potentials}}},
  keywords = {\_tablet,Artificial intelligence,Artificial neural networks,Containers,Data models,Pipelines,Task analysis,Tools},
  file = {/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/DUHHCVJD/Posoldova_2020_Machine Learning Pipelines.pdf;/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/ZS2XA5P2/9258455.html}
}

@article{precheltAutomaticEarlyStopping1998,
  title = {Automatic Early Stopping Using Cross Validation: Quantifying the Criteria},
  shorttitle = {Automatic Early Stopping Using Cross Validation},
  author = {Prechelt, Lutz},
  date = {1998-06-01},
  journaltitle = {Neural Networks},
  shortjournal = {Neural Networks},
  volume = {11},
  number = {4},
  pages = {761--767},
  issn = {0893-6080},
  doi = {10.1016/S0893-6080(98)00010-0},
  url = {https://www.sciencedirect.com/science/article/pii/S0893608098000100},
  urldate = {2023-08-02},
  abstract = {Cross validation can be used to detect when overfitting starts during supervised training of a neural network; training is then stopped before convergence to avoid the overfitting (`early stopping'). The exact criterion used for cross validation based early stopping, however, is chosen in an ad-hoc fashion by most researchers or training is stopped interactively. To aid a more well-founded selection of the stopping criterion, 14 different automatic stopping criteria from three classes were evaluated empirically for their efficiency and effectiveness in 12 different classification and approximation tasks using multi-layer perceptrons with RPROP training. The experiments show that, on average, slower stopping criteria allow for small improvements in generalization (in the order of 4\%), but cost about a factor of 4 longer in training time.},
  langid = {english},
  keywords = {\_tablet,Cross validation,Early stopping,Empirical study,Generalization,Overfitting,Supervised learning},
  file = {/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/SF72UPQ2/Prechelt_1998_Automatic early stopping using cross validation.pdf;/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/4DAK9L4Z/S0893608098000100.html}
}

@online{rivolliCharacterizingClassificationDatasets2019,
  title = {Characterizing Classification Datasets: A Study of Meta-Features for Meta-Learning},
  shorttitle = {Characterizing Classification Datasets},
  author = {Rivolli, Adriano and Garcia, Luís P. F. and Soares, Carlos and Vanschoren, Joaquin and family=Carvalho, given=André C. P. L. F., prefix=de, useprefix=true},
  date = {2019-08-26},
  eprint = {1808.10406},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1808.10406},
  url = {http://arxiv.org/abs/1808.10406},
  urldate = {2023-01-25},
  abstract = {Meta-learning is increasingly used to support the recommendation of machine learning algorithms and their configurations. Such recommendations are made based on meta-data, consisting of performance evaluations of algorithms on prior datasets, as well as characterizations of these datasets. These characterizations, also called meta-features, describe properties of the data which are predictive for the performance of machine learning algorithms trained on them. Unfortunately, despite being used in a large number of studies, meta-features are not uniformly described, organized and computed, making many empirical studies irreproducible and hard to compare. This paper aims to deal with this by systematizing and standardizing data characterization measures for classification datasets used in meta-learning. Moreover, it presents MFE, a new tool for extracting meta-features from datasets and identifying more subtle reproducibility issues in the literature, proposing guidelines for data characterization that strengthen reproducible empirical research in meta-learning.},
  pubstate = {preprint},
  keywords = {\_tablet,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/RBLAW9V5/Rivolli et al_2019_Characterizing classification datasets.pdf;/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/GZWP5W9J/1808.html}
}

@online{rombachHighResolutionImageSynthesis2022,
  title = {High-{{Resolution Image Synthesis}} with {{Latent Diffusion Models}}},
  author = {Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Björn},
  date = {2022-04-13},
  eprint = {2112.10752},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2112.10752},
  url = {http://arxiv.org/abs/2112.10752},
  urldate = {2023-07-22},
  abstract = {By decomposing the image formation process into a sequential application of denoising autoencoders, diffusion models (DMs) achieve state-of-the-art synthesis results on image data and beyond. Additionally, their formulation allows for a guiding mechanism to control the image generation process without retraining. However, since these models typically operate directly in pixel space, optimization of powerful DMs often consumes hundreds of GPU days and inference is expensive due to sequential evaluations. To enable DM training on limited computational resources while retaining their quality and flexibility, we apply them in the latent space of powerful pretrained autoencoders. In contrast to previous work, training diffusion models on such a representation allows for the first time to reach a near-optimal point between complexity reduction and detail preservation, greatly boosting visual fidelity. By introducing cross-attention layers into the model architecture, we turn diffusion models into powerful and flexible generators for general conditioning inputs such as text or bounding boxes and high-resolution synthesis becomes possible in a convolutional manner. Our latent diffusion models (LDMs) achieve a new state of the art for image inpainting and highly competitive performance on various tasks, including unconditional image generation, semantic scene synthesis, and super-resolution, while significantly reducing computational requirements compared to pixel-based DMs. Code is available at https://github.com/CompVis/latent-diffusion .},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/I5XNBHGL/Rombach et al_2022_High-Resolution Image Synthesis with Latent Diffusion Models.pdf;/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/XS89TD75/Rombach et al. - 2022 - High-Resolution Image Synthesis with Latent Diffus.pdf;/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/4Y2J95DE/2112.html}
}

@online{shankarOperationalizingMachineLearning2022,
  title = {Operationalizing {{Machine Learning}}: {{An Interview Study}}},
  shorttitle = {Operationalizing {{Machine Learning}}},
  author = {Shankar, Shreya and Garcia, Rolando and Hellerstein, Joseph M. and Parameswaran, Aditya G.},
  date = {2022-09-16},
  eprint = {2209.09125},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2209.09125},
  url = {http://arxiv.org/abs/2209.09125},
  urldate = {2022-12-07},
  abstract = {Organizations rely on machine learning engineers (MLEs) to operationalize ML, i.e., deploy and maintain ML pipelines in production. The process of operationalizing ML, or MLOps, consists of a continual loop of (i) data collection and labeling, (ii) experimentation to improve ML performance, (iii) evaluation throughout a multi-staged deployment process, and (iv) monitoring of performance drops in production. When considered together, these responsibilities seem staggering -- how does anyone do MLOps, what are the unaddressed challenges, and what are the implications for tool builders? We conducted semi-structured ethnographic interviews with 18 MLEs working across many applications, including chatbots, autonomous vehicles, and finance. Our interviews expose three variables that govern success for a production ML deployment: Velocity, Validation, and Versioning. We summarize common practices for successful ML experimentation, deployment, and sustaining production performance. Finally, we discuss interviewees' pain points and anti-patterns, with implications for tool design.},
  pubstate = {preprint},
  keywords = {\_tablet,Computer Science - Human-Computer Interaction,Computer Science - Machine Learning,Computer Science - Software Engineering},
  file = {/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/K7KRWSL2/Shankar et al_2022_Operationalizing Machine Learning.pdf;/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/AWM9SK8B/2209.html}
}

@article{shmueliExplainPredict2010a,
  title = {To {{Explain}} or to {{Predict}}?},
  author = {Shmueli, Galit},
  date = {2010-08-01},
  journaltitle = {Statistical Science},
  shortjournal = {Statist. Sci.},
  volume = {25},
  number = {3},
  eprint = {1101.0891},
  eprinttype = {arxiv},
  eprintclass = {stat},
  issn = {0883-4237},
  doi = {10.1214/10-STS330},
  url = {http://arxiv.org/abs/1101.0891},
  urldate = {2023-03-14},
  abstract = {Statistical modeling is a powerful tool for developing and testing theories by way of causal explanation, prediction, and description. In many disciplines there is near-exclusive use of statistical modeling for causal explanation and the assumption that models with high explanatory power are inherently of high predictive power. Conflation between explanation and prediction is common, yet the distinction must be understood for progressing scientific knowledge. While this distinction has been recognized in the philosophy of science, the statistical literature lacks a thorough discussion of the many differences that arise in the process of modeling for an explanatory versus a predictive goal. The purpose of this article is to clarify the distinction between explanatory and predictive modeling, to discuss its sources, and to reveal the practical implications of the distinction to each step in the modeling process.},
  keywords = {Statistics - Methodology},
  file = {/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/AAY68PXV/Shmueli_2010_To Explain or to Predict.pdf;/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/DT7EAVTS/1101.html}
}

@inproceedings{smedsDevOpsDefinitionPerceived2015,
  title = {{{DevOps}}: {{A Definition}} and {{Perceived Adoption Impediments}}},
  shorttitle = {{{DevOps}}},
  booktitle = {Agile {{Processes}} in {{Software Engineering}} and {{Extreme Programming}}},
  author = {Smeds, Jens and Nybom, Kristian and Porres, Ivan},
  editor = {Lassenius, Casper and Dingsøyr, Torgeir and Paasivaara, Maria},
  date = {2015},
  series = {Lecture {{Notes}} in {{Business Information Processing}}},
  pages = {166--177},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-18612-2_14},
  abstract = {As the interest in DevOps continues to grow, there is an increasing need for software organizations to understand how to adopt it successfully. This study has as objective to clarify the concept and provide insight into existing challenges of adopting DevOps. First, the existing literature is reviewed. A definition of DevOps is then formed based on the literature by breaking down the concept into its defining characteristics. We interview 13 subjects in a software company adopting DevOps and, finally, we present 11 impediments for the company’s DevOps adoption that were identified based on the interviews.},
  isbn = {978-3-319-18612-2},
  langid = {english},
  keywords = {Cloud Service,Continuous Delivery,Cultural Aspect,Service Failure,Software Process Improvement},
  file = {/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/TGE2W5BX/Smeds et al_2015_DevOps.pdf}
}

@online{stabilityaiStableDiffusionPublic2022,
  title = {Stable {{Diffusion Public Release}}},
  author = {{Stability AI}},
  date = {2022-08-22},
  url = {https://stability.ai/blog/stable-diffusion-public-release},
  urldate = {2023-07-24},
  abstract = {We are delighted to announce the public release of Stable Diffusion and the launch of DreamStudio Lite.},
  langid = {british},
  organization = {{Stability AI}},
  file = {/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/MM67JQZT/stable-diffusion-public-release.html}
}

@article{strubellEnergyPolicyConsiderations2020,
  title = {Energy and {{Policy Considerations}} for {{Modern Deep Learning Research}}},
  author = {Strubell, Emma and Ganesh, Ananya and McCallum, Andrew},
  date = {2020-04-03},
  journaltitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {34},
  number = {09},
  pages = {13693--13696},
  issn = {2374-3468},
  doi = {10.1609/aaai.v34i09.7123},
  url = {https://ojs.aaai.org/index.php/AAAI/article/view/7123},
  urldate = {2023-07-29},
  abstract = {The field of artificial intelligence has experienced a dramatic methodological shift towards large neural networks trained on plentiful data. This shift has been fueled by recent advances in hardware and techniques enabling remarkable levels of computation, resulting in impressive advances in AI across many applications. However, the massive computation required to obtain these exciting results is costly both financially, due to the price of specialized hardware and electricity or cloud compute time, and to the environment, as a result of non-renewable energy used to fuel modern tensor processing hardware. In a paper published this year at ACL, we brought this issue to the attention of NLP researchers by quantifying the approximate financial and environmental costs of training and tuning neural network models for NLP (Strubell, Ganesh, and McCallum 2019). In this extended abstract, we briefly summarize our findings in NLP, incorporating updated estimates and broader information from recent related publications, and provide actionable recommendations to reduce costs and improve equity in the machine learning and artificial intelligence community.},
  issue = {09},
  langid = {english},
  keywords = {\_tablet},
  file = {/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/GYKMMFTG/Strubell et al_2020_Energy and Policy Considerations for Modern Deep Learning Research.pdf}
}

@online{thompsonComputationalLimitsDeep2022,
  title = {The {{Computational Limits}} of {{Deep Learning}}},
  author = {Thompson, Neil C. and Greenewald, Kristjan and Lee, Keeheon and Manso, Gabriel F.},
  date = {2022-07-27},
  eprint = {2007.05558},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/2007.05558},
  urldate = {2023-07-29},
  abstract = {Deep learning’s recent history has been one of achievement: from triumphing over humans in the game of Go to world-leading performance in image classification, voice recognition, translation, and other tasks. But this progress has come with a voracious appetite for computing power. This article catalogs the extent of this dependency, showing that progress across a wide variety of applications is strongly reliant on increases in computing power. Extrapolating forward this reliance reveals that progress along current lines is rapidly becoming economically, technically, and environmentally unsustainable. Thus, continued progress in these applications will require dramatically more computationallyefficient methods, which will either have to come from changes to deep learning or from moving to other machine learning methods.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/L9G7ZIJD/Thompson et al_2022_The Computational Limits of Deep Learning.pdf}
}

@online{touvronLLaMAOpenEfficient2023,
  title = {{{LLaMA}}: {{Open}} and {{Efficient Foundation Language Models}}},
  shorttitle = {{{LLaMA}}},
  author = {Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timothée and Rozière, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and Rodriguez, Aurelien and Joulin, Armand and Grave, Edouard and Lample, Guillaume},
  date = {2023-02-27},
  eprint = {2302.13971},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2302.13971},
  url = {http://arxiv.org/abs/2302.13971},
  urldate = {2023-07-24},
  abstract = {We introduce LLaMA, a collection of foundation language models ranging from 7B to 65B parameters. We train our models on trillions of tokens, and show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets. In particular, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks, and LLaMA-65B is competitive with the best models, Chinchilla-70B and PaLM-540B. We release all our models to the research community.},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/7QL95LTK/Touvron et al_2023_LLaMA.pdf;/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/BUKAMHIP/2302.html}
}

@article{wallerIncludingPerformanceBenchmarks2015,
  title = {Including {{Performance Benchmarks}} into {{Continuous Integration}} to {{Enable DevOps}}},
  author = {Waller, Jan and Ehmke, Nils C. and Hasselbring, Wilhelm},
  date = {2015-04-03},
  journaltitle = {ACM SIGSOFT Software Engineering Notes},
  shortjournal = {SIGSOFT Softw. Eng. Notes},
  volume = {40},
  number = {2},
  pages = {1--4},
  issn = {0163-5948},
  doi = {10.1145/2735399.2735416},
  url = {https://doi.org/10.1145/2735399.2735416},
  urldate = {2023-01-17},
  abstract = {The DevOps movement intends to improve communication, collaboration, and integration between software developers (Dev) and IT operations professionals (Ops). Automation of software quality assurance is key to DevOps success. We present how automated performance benchmarks may be included into continuous integration. As an example, we report on regression benchmarks for application monitoring frameworks and illustrate the inclusion of automated benchmarks into continuous integration setups.},
  keywords = {Jenkins,Kieker,MooBench},
  file = {/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/L5MUF3HG/Waller et al_2015_Including Performance Benchmarks into Continuous Integration to Enable DevOps.pdf}
}

@inproceedings{wirthCrispdmStandardProcess2000,
  title = {Crisp-Dm: Towards a Standard Process Modell for Data Mining},
  shorttitle = {Crisp-Dm},
  author = {Wirth, R. and Hipp, Jochen},
  date = {2000},
  url = {https://www.semanticscholar.org/paper/Crisp-dm%3A-towards-a-standard-process-modell-for-Wirth-Hipp/48b9293cfd4297f855867ca278f7069abc6a9c24},
  urldate = {2023-06-15},
  abstract = {The CRISP-DM (CRoss Industry Standard Process for Data Mining) project proposed a comprehensive process model for carrying out data mining projects. The process model is independent of both the industry sector and the technology used. In this paper we argue in favor of a standard process model for data mining and report some experiences with the CRISP-DM process model in practice. We applied and tested the CRISP-DM methodology in a response modeling application project. The final goal of the project was to specify a process which can be reliably and efficiently repeated by different people and adapted to different situations. The initial projects were performed by experienced data mining people; future projects are to be performed by people with lower technical skills and with very little time to experiment with different approaches. It turned out, that the CRISP-DM methodology with its distinction of generic and specialized process models provides both the structure and the flexibility necessary to suit the needs of both groups. The generic CRISP-DM process model is useful for planning, communication within and outside the project team, and documentation. The generic check-lists are helpful even for experienced people. The generic process model provides an excellent foundation for developing a specialized process model which prescribes the steps to be taken in detail and which gives practical advice for all these steps.},
  file = {C\:\\Users\\master\\Zotero\\storage\\3NW8IB87\\Wirth_Hipp_2000_Crisp-dm.pdf}
}

@inproceedings{xanthopoulosPuttingHumanBack2020,
  title = {Putting the {{Human Back}} in the {{AutoML Loop}}},
  author = {Xanthopoulos, Iordanis and Tsamardinos, I. and Christophides, V. and Simon, Eric and Salinger, Alejandro},
  date = {2020},
  url = {https://www.semanticscholar.org/paper/Putting-the-Human-Back-in-the-AutoML-Loop-Xanthopoulos-Tsamardinos/7293b51020d422ff14515abc7c91962713ea8391},
  urldate = {2023-01-25},
  abstract = {Automated Machine Learning (AutoML) is a rapidly rising subfield of Machine Learning. AutoML aims to fully automate the machine learning process end-to-end, democratizing Machine Learning to non-experts and drastically increasing the productivity of expert analysts. So far, most comparisons of AutoML systems focus on quantitative criteria such as predictive performance and execution time. In this paper, we examine AutoML services for predictive modeling tasks from a user’s perspective, going beyond predictive performance. We present a wide palette of criteria and dimensions on which to evaluate and compare these services as a user. This qualitative comparative methodology is applied on seven AutoML systems, namely Auger.AI, BigML, H2O’s Driverless AI, Darwin, Just Add Data Bio, RapidMiner, and Watson. The comparison indicates the strengths and weaknesses of each service, the needs that it covers, the segment of users that is most appropriate for, and the possibilities for improvements.},
  eventtitle = {{{EDBT}}/{{ICDT Workshops}}},
  keywords = {\_tablet},
  file = {/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/SA4IQ5AH/Xanthopoulos et al_2020_Putting the Human Back in the AutoML Loop.pdf}
}

@article{yangHyperparameterOptimizationMachine2020,
  title = {On {{Hyperparameter Optimization}} of {{Machine Learning Algorithms}}: {{Theory}} and {{Practice}}},
  shorttitle = {On {{Hyperparameter Optimization}} of {{Machine Learning Algorithms}}},
  author = {Yang, Li and Shami, Abdallah},
  date = {2020-11},
  journaltitle = {Neurocomputing},
  shortjournal = {Neurocomputing},
  volume = {415},
  eprint = {2007.15745},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  pages = {295--316},
  issn = {09252312},
  doi = {10.1016/j.neucom.2020.07.061},
  url = {http://arxiv.org/abs/2007.15745},
  urldate = {2023-01-25},
  abstract = {Machine learning algorithms have been used widely in various applications and areas. To fit a machine learning model into different problems, its hyper-parameters must be tuned. Selecting the best hyper-parameter configuration for machine learning models has a direct impact on the model's performance. It often requires deep knowledge of machine learning algorithms and appropriate hyper-parameter optimization techniques. Although several automatic optimization techniques exist, they have different strengths and drawbacks when applied to different types of problems. In this paper, optimizing the hyper-parameters of common machine learning models is studied. We introduce several state-of-the-art optimization techniques and discuss how to apply them to machine learning algorithms. Many available libraries and frameworks developed for hyper-parameter optimization problems are provided, and some open challenges of hyper-parameter optimization research are also discussed in this paper. Moreover, experiments are conducted on benchmark datasets to compare the performance of different optimization methods and provide practical examples of hyper-parameter optimization. This survey paper will help industrial users, data analysts, and researchers to better develop machine learning models by identifying the proper hyper-parameter configurations effectively.},
  keywords = {\_tablet,{68T01, 90C31},C.2.0,Computer Science - Machine Learning,I.2.0,I.2.2,Statistics - Machine Learning},
  file = {/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/6TZA7J63/Yang_Shami_2020_On Hyperparameter Optimization of Machine Learning Algorithms.pdf;/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/CNXX8V4E/2007.html}
}

@article{yangIoTDataAnalytics2022,
  title = {{{IoT Data Analytics}} in {{Dynamic Environments}}: {{From An Automated Machine Learning Perspective}}},
  shorttitle = {{{IoT Data Analytics}} in {{Dynamic Environments}}},
  author = {Yang, Li and Shami, Abdallah},
  date = {2022-11},
  journaltitle = {Engineering Applications of Artificial Intelligence},
  shortjournal = {Engineering Applications of Artificial Intelligence},
  volume = {116},
  eprint = {2209.08018},
  eprinttype = {arxiv},
  eprintclass = {cs, eess},
  pages = {105366},
  issn = {09521976},
  doi = {10.1016/j.engappai.2022.105366},
  url = {http://arxiv.org/abs/2209.08018},
  urldate = {2023-01-25},
  abstract = {With the wide spread of sensors and smart devices in recent years, the data generation speed of the Internet of Things (IoT) systems has increased dramatically. In IoT systems, massive volumes of data must be processed, transformed, and analyzed on a frequent basis to enable various IoT services and functionalities. Machine Learning (ML) approaches have shown their capacity for IoT data analytics. However, applying ML models to IoT data analytics tasks still faces many difficulties and challenges, specifically, effective model selection, design/tuning, and updating, which have brought massive demand for experienced data scientists. Additionally, the dynamic nature of IoT data may introduce concept drift issues, causing model performance degradation. To reduce human efforts, Automated Machine Learning (AutoML) has become a popular field that aims to automatically select, construct, tune, and update machine learning models to achieve the best performance on specified tasks. In this paper, we conduct a review of existing methods in the model selection, tuning, and updating procedures in the area of AutoML in order to identify and summarize the optimal solutions for every step of applying ML algorithms to IoT data analytics. To justify our findings and help industrial users and researchers better implement AutoML approaches, a case study of applying AutoML to IoT anomaly detection problems is conducted in this work. Lastly, we discuss and classify the challenges and research directions for this domain.},
  keywords = {\_tablet,{68T01, 90C31},C.2.0,Computer Science - Cryptography and Security,Computer Science - Machine Learning,Computer Science - Networking and Internet Architecture,Electrical Engineering and Systems Science - Systems and Control,I.2.0,I.2.2},
  file = {/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/MHGKKJW5/Yang_Shami_2022_IoT Data Analytics in Dynamic Environments.pdf;/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/AFUU3C7X/2209.html}
}

@article{zahariaAcceleratingMachineLearning2018,
  title = {Accelerating the {{Machine Learning Lifecycle}} with {{MLflow}}},
  author = {Zaharia, M. and Chen, A. and Davidson, A. and Ghodsi, A. and Hong, S. and Konwinski, A. and Murching, Siddharth and Nykodym, Tomas and Ogilvie, Paul and Parkhe, Mani and Xie, Fen and Zumar, Corey},
  date = {2018},
  journaltitle = {IEEE Data Eng. Bull.},
  url = {https://www.semanticscholar.org/paper/Accelerating-the-Machine-Learning-Lifecycle-with-Zaharia-Chen/b2e0b79e6f180af2e0e559f2b1faba66b2bd578a},
  urldate = {2023-03-14},
  abstract = {Machine learning development creates multiple new challenges that are not present in a traditional software development lifecycle. These include keeping track of the myriad inputs to an ML application (e.g., data versions, code and tuning parameters), reproducing results, and production deployment. In this paper, we summarize these challenges from our experience with Databricks customers, and describe MLflow, an open source platform we recently launched to streamline the machine learning lifecycle. MLflow covers three key challenges: experimentation, reproducibility, and model deployment, using generic APIs that work with any ML library, algorithm and programming language. The project has a rapidly growing open source community, with over 50 contributors since its launch in June 2018.},
  keywords = {\_tablet},
  file = {/Users/al/Library/CloudStorage/OneDrive-Personal/Apps/Zotero/storage/6RA7FM6Z/Zaharia et al_2018_Accelerating the Machine Learning Lifecycle with MLflow.pdf}
}
